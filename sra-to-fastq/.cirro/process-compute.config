/*
 * Cirro compute configuration overrides
 * 
 * This file is merged with the pipeline's nextflow.config
 * and can override settings for the Cirro/AWS environment.
 */

// Process-specific settings
process {
    // Default container for all processes
    container = "quay.io/biocontainers/sra-tools:3.0.3--h87f3376_0"
    
    // Retry failed jobs with more memory (useful for variable SRA file sizes)
    errorStrategy = 'retry'
    maxRetries = 1
    
    // Memory scaling on retry
    memory = { 64.GB * task.attempt }
    
    // Process-specific overrides
    withName: 'SRA_TO_FASTQ' {
        // SRA files can be large - allocate plenty of disk
        // Note: fasterq-dump has internal disk limit checks that may cause errors
        // if insufficient space is detected. Ensure adequate disk allocation.
        disk = '25000 GB' //This is a bit excessive ---> overridden in main.nf 
        memory = '32 GB'
    }
}

// AWS Batch settings (Cirro runs on AWS)
aws {
    batch {
        // Use spot instances for cost savings
        jobRole = null  // Cirro manages this
    }
}
