/*
 * Cirro compute configuration overrides
 * 
 * This file is merged with the pipeline's nextflow.config
 * and can override settings for the Cirro/AWS environment.
 */

// Process-specific settings
process {
    // Retry failed jobs with more memory (useful for variable SRA file sizes)
    errorStrategy = 'retry'
    maxRetries = 1
    
    // Memory scaling on retry
    memory = { 64.GB * task.attempt }
    
    // Process-specific overrides
    withName: 'EXTRACT_FASTQ' {
        // SRA files can be large - allocate plenty of disk
        // Note: fasterq-dump has internal disk limit checks that may cause errors
        // if insufficient space is detected. Ensure adequate disk allocation.
        disk = '25000 GB'
        memory = '32 GB'
    }

    withName: 'COMPRESS_FASTQ' {
        // Compression is lighter-weight; use less memory
        memory = '16 GB'
    }
}

// AWS Batch settings (Cirro runs on AWS)
aws {
    batch {
        // Use spot instances for cost savings
        jobRole = null  // Cirro manages this
    }
}
