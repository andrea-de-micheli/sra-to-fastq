/*
 * Cirro compute configuration overrides
 * 
 * This file is merged with the pipeline's nextflow.config
 * and can override settings for the Cirro/AWS environment.
 */

// Process-specific settings
process {
    // Note: SRA_TO_FASTQ uses conda instead of container
    // Default container removed to allow conda directive in main.nf
    
    // Retry failed jobs with more memory (useful for variable SRA file sizes)
    errorStrategy = 'retry'
    maxRetries = 2
    
    // Memory scaling on retry
    memory = { 32.GB * task.attempt }
    
    // Process-specific overrides
    withName: 'SRA_TO_FASTQ' {
        // SRA files can be large - allocate plenty of disk
        // Note: fasterq-dump has internal disk limit checks that may cause errors
        // if insufficient space is detected. Ensure adequate disk allocation.
        disk = '25000 GB' //This is a bit excessive ---> overridden in main.nf 
        memory = '32 GB'
        // No container - using conda instead (defined in main.nf)
    }
}

// AWS Batch settings (Cirro runs on AWS)
aws {
    batch {
        // Use spot instances for cost savings
        jobRole = null  // Cirro manages this
    }
}
